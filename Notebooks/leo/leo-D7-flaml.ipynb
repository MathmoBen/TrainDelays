{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d942cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 70)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from pathlib import Path\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from flaml import AutoML\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779c5120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN_SERVICE_CODE_AFFECTED</th>\n",
       "      <th>SERVICE_GROUP_CODE_AFFECTED</th>\n",
       "      <th>ENGLISH_DAY_TYPE</th>\n",
       "      <th>APP_TIMETABLE_FLAG_AFF</th>\n",
       "      <th>UNIT_CLASS_AFFECTED</th>\n",
       "      <th>INCIDENT_REASON</th>\n",
       "      <th>PERFORMANCE_EVENT_CODE</th>\n",
       "      <th>PFPI_MINUTES</th>\n",
       "      <th>Lat_OR</th>\n",
       "      <th>Lon_OR</th>\n",
       "      <th>Lat_DES</th>\n",
       "      <th>Lon_DES</th>\n",
       "      <th>ORIG_MONTH_SIN</th>\n",
       "      <th>ORIG_MONTH_COS</th>\n",
       "      <th>ORIG_DAY_SIN</th>\n",
       "      <th>ORIG_DAY_COS</th>\n",
       "      <th>ORIG_HOUR_SIN</th>\n",
       "      <th>ORIG_HOUR_COS</th>\n",
       "      <th>ORIG_MINUTE_SIN</th>\n",
       "      <th>ORIG_MINUTE_COS</th>\n",
       "      <th>DEST_MONTH_SIN</th>\n",
       "      <th>DEST_MONTH_COS</th>\n",
       "      <th>DEST_DAY_SIN</th>\n",
       "      <th>DEST_DAY_COS</th>\n",
       "      <th>DEST_HOUR_SIN</th>\n",
       "      <th>DEST_HOUR_COS</th>\n",
       "      <th>DEST_MINUTE_SIN</th>\n",
       "      <th>DEST_MINUTE_COS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22215003</td>\n",
       "      <td>EK03</td>\n",
       "      <td>BH</td>\n",
       "      <td>Y</td>\n",
       "      <td>375.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.54650</td>\n",
       "      <td>-0.10408</td>\n",
       "      <td>51.54650</td>\n",
       "      <td>-0.10408</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>-0.669131</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>0.951057</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-9.781476e-01</td>\n",
       "      <td>0.207912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22215003</td>\n",
       "      <td>EK03</td>\n",
       "      <td>BH</td>\n",
       "      <td>Y</td>\n",
       "      <td>375.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.54650</td>\n",
       "      <td>-0.10408</td>\n",
       "      <td>51.54612</td>\n",
       "      <td>-0.07513</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>-2.079117e-01</td>\n",
       "      <td>-0.978148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22218000</td>\n",
       "      <td>EK99</td>\n",
       "      <td>BH</td>\n",
       "      <td>Y</td>\n",
       "      <td>375.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.54612</td>\n",
       "      <td>-0.07513</td>\n",
       "      <td>51.51947</td>\n",
       "      <td>-0.05975</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.913545</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22218000</td>\n",
       "      <td>EK99</td>\n",
       "      <td>BH</td>\n",
       "      <td>Y</td>\n",
       "      <td>375.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.54612</td>\n",
       "      <td>-0.07513</td>\n",
       "      <td>51.54612</td>\n",
       "      <td>-0.07513</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22218000</td>\n",
       "      <td>EK99</td>\n",
       "      <td>BH</td>\n",
       "      <td>Y</td>\n",
       "      <td>375.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.54612</td>\n",
       "      <td>-0.07513</td>\n",
       "      <td>51.54612</td>\n",
       "      <td>-0.07513</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>-4.067366e-01</td>\n",
       "      <td>-0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493246</th>\n",
       "      <td>22214000</td>\n",
       "      <td>EK01</td>\n",
       "      <td>WD</td>\n",
       "      <td>Y</td>\n",
       "      <td>378.0</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>51.55548</td>\n",
       "      <td>-0.15136</td>\n",
       "      <td>51.53250</td>\n",
       "      <td>-0.24454</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>-0.669131</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>6.691306e-01</td>\n",
       "      <td>-0.743145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493247</th>\n",
       "      <td>22204000</td>\n",
       "      <td>EK01</td>\n",
       "      <td>WD</td>\n",
       "      <td>Y</td>\n",
       "      <td>378.0</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.52652</td>\n",
       "      <td>-0.23569</td>\n",
       "      <td>51.53250</td>\n",
       "      <td>-0.24454</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>-0.669131</td>\n",
       "      <td>-0.913545</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-5.877853e-01</td>\n",
       "      <td>0.809017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493248</th>\n",
       "      <td>22214000</td>\n",
       "      <td>EK01</td>\n",
       "      <td>WD</td>\n",
       "      <td>Y</td>\n",
       "      <td>378.0</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.49141</td>\n",
       "      <td>-0.27553</td>\n",
       "      <td>51.52274</td>\n",
       "      <td>-0.25487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>-0.669131</td>\n",
       "      <td>-0.978148</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493249</th>\n",
       "      <td>22214000</td>\n",
       "      <td>EK01</td>\n",
       "      <td>WD</td>\n",
       "      <td>Y</td>\n",
       "      <td>378.0</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.49141</td>\n",
       "      <td>-0.27553</td>\n",
       "      <td>51.52274</td>\n",
       "      <td>-0.25487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-4.067366e-01</td>\n",
       "      <td>-0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493250</th>\n",
       "      <td>22204000</td>\n",
       "      <td>EK01</td>\n",
       "      <td>WD</td>\n",
       "      <td>Y</td>\n",
       "      <td>378.0</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.52652</td>\n",
       "      <td>-0.23569</td>\n",
       "      <td>51.53250</td>\n",
       "      <td>-0.24454</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>0.951057</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-7.431448e-01</td>\n",
       "      <td>-0.669131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493251 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TRAIN_SERVICE_CODE_AFFECTED SERVICE_GROUP_CODE_AFFECTED  \\\n",
       "0                          22215003                        EK03   \n",
       "1                          22215003                        EK03   \n",
       "2                          22218000                        EK99   \n",
       "3                          22218000                        EK99   \n",
       "4                          22218000                        EK99   \n",
       "...                             ...                         ...   \n",
       "493246                     22214000                        EK01   \n",
       "493247                     22204000                        EK01   \n",
       "493248                     22214000                        EK01   \n",
       "493249                     22214000                        EK01   \n",
       "493250                     22204000                        EK01   \n",
       "\n",
       "       ENGLISH_DAY_TYPE APP_TIMETABLE_FLAG_AFF  UNIT_CLASS_AFFECTED  \\\n",
       "0                    BH                      Y                375.0   \n",
       "1                    BH                      Y                375.0   \n",
       "2                    BH                      Y                375.0   \n",
       "3                    BH                      Y                375.0   \n",
       "4                    BH                      Y                375.0   \n",
       "...                 ...                    ...                  ...   \n",
       "493246               WD                      Y                378.0   \n",
       "493247               WD                      Y                378.0   \n",
       "493248               WD                      Y                378.0   \n",
       "493249               WD                      Y                378.0   \n",
       "493250               WD                      Y                378.0   \n",
       "\n",
       "       INCIDENT_REASON PERFORMANCE_EVENT_CODE  PFPI_MINUTES    Lat_OR  \\\n",
       "0                    M                      M           9.0  51.54650   \n",
       "1                    M                      M           6.0  51.54650   \n",
       "2                    M                      M           0.0  51.54612   \n",
       "3                    M                      M           0.0  51.54612   \n",
       "4                    M                      M           0.0  51.54612   \n",
       "...                ...                    ...           ...       ...   \n",
       "493246               R                      M           5.0  51.55548   \n",
       "493247               R                      M           4.0  51.52652   \n",
       "493248               R                      M           7.0  51.49141   \n",
       "493249               R                      M           4.0  51.49141   \n",
       "493250               R                      M           4.0  51.52652   \n",
       "\n",
       "         Lon_OR   Lat_DES  Lon_DES  ORIG_MONTH_SIN  ORIG_MONTH_COS  \\\n",
       "0      -0.10408  51.54650 -0.10408        0.406737        0.913545   \n",
       "1      -0.10408  51.54612 -0.07513        0.406737        0.913545   \n",
       "2      -0.07513  51.51947 -0.05975        0.406737        0.913545   \n",
       "3      -0.07513  51.54612 -0.07513        0.406737        0.913545   \n",
       "4      -0.07513  51.54612 -0.07513        0.406737        0.913545   \n",
       "...         ...       ...      ...             ...             ...   \n",
       "493246 -0.15136  51.53250 -0.24454        0.500000        0.866025   \n",
       "493247 -0.23569  51.53250 -0.24454        0.500000        0.866025   \n",
       "493248 -0.27553  51.52274 -0.25487        0.500000        0.866025   \n",
       "493249 -0.27553  51.52274 -0.25487        0.500000        0.866025   \n",
       "493250 -0.23569  51.53250 -0.24454        0.500000        0.866025   \n",
       "\n",
       "        ORIG_DAY_SIN  ORIG_DAY_COS  ORIG_HOUR_SIN  ORIG_HOUR_COS  \\\n",
       "0           0.207912      0.978148       0.743145      -0.669131   \n",
       "1           0.207912      0.978148       0.994522      -0.104528   \n",
       "2           0.207912      0.978148       0.994522      -0.104528   \n",
       "3           0.207912      0.978148       0.994522      -0.104528   \n",
       "4           0.207912      0.978148       0.994522      -0.104528   \n",
       "...              ...           ...            ...            ...   \n",
       "493246      0.587785     -0.809017       0.743145      -0.669131   \n",
       "493247      0.587785     -0.809017       0.743145      -0.669131   \n",
       "493248      0.587785     -0.809017       0.743145      -0.669131   \n",
       "493249      0.587785     -0.809017       0.669131      -0.743145   \n",
       "493250      0.587785     -0.809017       0.669131      -0.743145   \n",
       "\n",
       "        ORIG_MINUTE_SIN  ORIG_MINUTE_COS  DEST_MONTH_SIN  DEST_MONTH_COS  \\\n",
       "0             -0.309017         0.951057        0.406737        0.913545   \n",
       "1             -0.951057        -0.309017        0.406737        0.913545   \n",
       "2             -0.913545         0.406737        0.406737        0.913545   \n",
       "3             -0.994522        -0.104528        0.406737        0.913545   \n",
       "4             -0.809017         0.587785        0.406737        0.913545   \n",
       "...                 ...              ...             ...             ...   \n",
       "493246         0.809017        -0.587785        0.500000        0.866025   \n",
       "493247        -0.913545         0.406737        0.500000        0.866025   \n",
       "493248        -0.978148         0.207912        0.500000        0.866025   \n",
       "493249         0.978148        -0.207912        0.500000        0.866025   \n",
       "493250         0.951057        -0.309017        0.500000        0.866025   \n",
       "\n",
       "        DEST_DAY_SIN  DEST_DAY_COS  DEST_HOUR_SIN  DEST_HOUR_COS  \\\n",
       "0           0.207912      0.978148       0.669131      -0.743145   \n",
       "1           0.207912      0.978148       0.978148      -0.207912   \n",
       "2           0.207912      0.978148       0.978148      -0.207912   \n",
       "3           0.207912      0.978148       0.978148      -0.207912   \n",
       "4           0.207912      0.978148       0.978148      -0.207912   \n",
       "...              ...           ...            ...            ...   \n",
       "493246      0.587785     -0.809017       0.669131      -0.743145   \n",
       "493247      0.587785     -0.809017       0.669131      -0.743145   \n",
       "493248      0.587785     -0.809017       0.669131      -0.743145   \n",
       "493249      0.587785     -0.809017       0.669131      -0.743145   \n",
       "493250      0.587785     -0.809017       0.669131      -0.743145   \n",
       "\n",
       "        DEST_MINUTE_SIN  DEST_MINUTE_COS  \n",
       "0         -9.781476e-01         0.207912  \n",
       "1         -2.079117e-01        -0.978148  \n",
       "2          5.665539e-16        -1.000000  \n",
       "3          5.000000e-01         0.866025  \n",
       "4         -4.067366e-01        -0.913545  \n",
       "...                 ...              ...  \n",
       "493246     6.691306e-01        -0.743145  \n",
       "493247    -5.877853e-01         0.809017  \n",
       "493248    -8.660254e-01         0.500000  \n",
       "493249    -4.067366e-01        -0.913545  \n",
       "493250    -7.431448e-01        -0.669131  \n",
       "\n",
       "[493251 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/clean_data_final.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c559c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493251 entries, 0 to 493250\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   TRAIN_SERVICE_CODE_AFFECTED  493251 non-null  int64  \n",
      " 1   SERVICE_GROUP_CODE_AFFECTED  493251 non-null  object \n",
      " 2   ENGLISH_DAY_TYPE             493251 non-null  object \n",
      " 3   APP_TIMETABLE_FLAG_AFF       493251 non-null  object \n",
      " 4   UNIT_CLASS_AFFECTED          493251 non-null  float64\n",
      " 5   INCIDENT_REASON              493251 non-null  object \n",
      " 6   PERFORMANCE_EVENT_CODE       493251 non-null  object \n",
      " 7   PFPI_MINUTES                 493251 non-null  float64\n",
      " 8   Lat_OR                       493251 non-null  float64\n",
      " 9   Lon_OR                       493251 non-null  float64\n",
      " 10  Lat_DES                      493251 non-null  float64\n",
      " 11  Lon_DES                      493251 non-null  float64\n",
      " 12  ORIG_MONTH_SIN               493251 non-null  float64\n",
      " 13  ORIG_MONTH_COS               493251 non-null  float64\n",
      " 14  ORIG_DAY_SIN                 493251 non-null  float64\n",
      " 15  ORIG_DAY_COS                 493251 non-null  float64\n",
      " 16  ORIG_HOUR_SIN                493251 non-null  float64\n",
      " 17  ORIG_HOUR_COS                493251 non-null  float64\n",
      " 18  ORIG_MINUTE_SIN              493251 non-null  float64\n",
      " 19  ORIG_MINUTE_COS              493251 non-null  float64\n",
      " 20  DEST_MONTH_SIN               493251 non-null  float64\n",
      " 21  DEST_MONTH_COS               493251 non-null  float64\n",
      " 22  DEST_DAY_SIN                 493251 non-null  float64\n",
      " 23  DEST_DAY_COS                 493251 non-null  float64\n",
      " 24  DEST_HOUR_SIN                493251 non-null  float64\n",
      " 25  DEST_HOUR_COS                493251 non-null  float64\n",
      " 26  DEST_MINUTE_SIN              493251 non-null  float64\n",
      " 27  DEST_MINUTE_COS              493251 non-null  float64\n",
      "dtypes: float64(22), int64(1), object(5)\n",
      "memory usage: 105.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65035119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_transformer = MinMaxScaler()\n",
    "\n",
    "# cat_transformer = OneHotEncoder(handle_unknown='ignore', drop='if_binary')\n",
    "\n",
    "\n",
    "\n",
    "# def sin_transformer(period):\n",
    "#     return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "# def cos_transformer(period):\n",
    "#     return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num_transformer', num_transformer, ['Lat_OR', 'Lon_OR', 'Lat_DES', 'Lon_DES']),\n",
    "#     ('cat_transformer', cat_transformer, ['ENGLISH_DAY_TYPE', 'SERVICE_GROUP_CODE_AFFECTED', 'INCIDENT_REASON',\n",
    "#                                                         'UNIT_CLASS_AFFECTED', 'TRAIN_SERVICE_CODE_AFFECTED', \n",
    "#                                                      'PERFORMANCE_EVENT_CODE', \n",
    "#                                                      'APP_TIMETABLE_FLAG_AFF']),\n",
    "#     ('month_sin', sin_transformer(12), ['ORIG_MONTH', 'DEST_MONTH']),\n",
    "#     ('month_cos', cos_transformer(12), ['ORIG_MONTH', 'DEST_MONTH']),\n",
    "#     ('day_sin', sin_transformer(31), ['ORIG_DAY', 'DEST_DAY']),\n",
    "#     ('day_cos', cos_transformer(31), ['ORIG_DAY', 'DEST_DAY']),\n",
    "#     ('hour_sin', sin_transformer(24), ['ORIG_HOUR', 'DEST_HOUR']),\n",
    "#     ('hour_cos', cos_transformer(24), ['ORIG_HOUR', 'DEST_HOUR']),\n",
    "#     ('minute_sin', sin_transformer(60), ['ORIG_MINUTE', 'DSET_MINUTE']),\n",
    "#     ('minute_cos', cos_transformer(60), ['ORIG_MINUTE', 'DEST_MINUTE'])\n",
    "# ], sparse_threshold=0, remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01a5ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [&#x27;Lat_OR&#x27;, &#x27;Lon_OR&#x27;,\n",
       "                                                   &#x27;Lat_DES&#x27;, &#x27;Lon_DES&#x27;]),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;ENGLISH_DAY_TYPE&#x27;,\n",
       "                                                   &#x27;SERVICE_GROUP_CODE_AFFECTED&#x27;,\n",
       "                                                   &#x27;INCIDENT_REASON&#x27;,\n",
       "                                                   &#x27;UNIT_CLASS_AFFECTED&#x27;,\n",
       "                                                   &#x27;TRAIN_SERVICE_CODE_AFFECTED&#x27;,\n",
       "                                                   &#x27;PERFORMANCE_EVENT_CODE&#x27;,\n",
       "                                                   &#x27;APP_TIMETABLE_FLAG_AFF&#x27;])]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [&#x27;Lat_OR&#x27;, &#x27;Lon_OR&#x27;,\n",
       "                                                   &#x27;Lat_DES&#x27;, &#x27;Lon_DES&#x27;]),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;ENGLISH_DAY_TYPE&#x27;,\n",
       "                                                   &#x27;SERVICE_GROUP_CODE_AFFECTED&#x27;,\n",
       "                                                   &#x27;INCIDENT_REASON&#x27;,\n",
       "                                                   &#x27;UNIT_CLASS_AFFECTED&#x27;,\n",
       "                                                   &#x27;TRAIN_SERVICE_CODE_AFFECTED&#x27;,\n",
       "                                                   &#x27;PERFORMANCE_EVENT_CODE&#x27;,\n",
       "                                                   &#x27;APP_TIMETABLE_FLAG_AFF&#x27;])]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;minmaxscaler&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;Lat_OR&#x27;, &#x27;Lon_OR&#x27;, &#x27;Lat_DES&#x27;, &#x27;Lon_DES&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 [&#x27;ENGLISH_DAY_TYPE&#x27;,\n",
       "                                  &#x27;SERVICE_GROUP_CODE_AFFECTED&#x27;,\n",
       "                                  &#x27;INCIDENT_REASON&#x27;, &#x27;UNIT_CLASS_AFFECTED&#x27;,\n",
       "                                  &#x27;TRAIN_SERVICE_CODE_AFFECTED&#x27;,\n",
       "                                  &#x27;PERFORMANCE_EVENT_CODE&#x27;,\n",
       "                                  &#x27;APP_TIMETABLE_FLAG_AFF&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">minmaxscaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Lat_OR&#x27;, &#x27;Lon_OR&#x27;, &#x27;Lat_DES&#x27;, &#x27;Lon_DES&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ENGLISH_DAY_TYPE&#x27;, &#x27;SERVICE_GROUP_CODE_AFFECTED&#x27;, &#x27;INCIDENT_REASON&#x27;, &#x27;UNIT_CLASS_AFFECTED&#x27;, &#x27;TRAIN_SERVICE_CODE_AFFECTED&#x27;, &#x27;PERFORMANCE_EVENT_CODE&#x27;, &#x27;APP_TIMETABLE_FLAG_AFF&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['Lat_OR', 'Lon_OR',\n",
       "                                                   'Lat_DES', 'Lon_DES']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['ENGLISH_DAY_TYPE',\n",
       "                                                   'SERVICE_GROUP_CODE_AFFECTED',\n",
       "                                                   'INCIDENT_REASON',\n",
       "                                                   'UNIT_CLASS_AFFECTED',\n",
       "                                                   'TRAIN_SERVICE_CODE_AFFECTED',\n",
       "                                                   'PERFORMANCE_EVENT_CODE',\n",
       "                                                   'APP_TIMETABLE_FLAG_AFF'])]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_transformer = MinMaxScaler()\n",
    "\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "transformer = make_column_transformer((num_transformer, ['Lat_OR','Lon_OR', 'Lat_DES','Lon_DES']),\n",
    "                                  (cat_transformer, ['ENGLISH_DAY_TYPE', 'SERVICE_GROUP_CODE_AFFECTED', 'INCIDENT_REASON',\n",
    "                                                        'UNIT_CLASS_AFFECTED', 'TRAIN_SERVICE_CODE_AFFECTED', \n",
    "                                                     'PERFORMANCE_EVENT_CODE', \n",
    "                                                     'APP_TIMETABLE_FLAG_AFF']),\n",
    "                                remainder = 'passthrough')\n",
    "\n",
    "\n",
    "pipe = Pipeline([('transformer', transformer)])\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3b2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='PFPI_MINUTES'), df['PFPI_MINUTES'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1540e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pipe.fit_transform(X_train)\n",
    "X_test_scaled = pipe.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd56368b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50655971,  0.5413115 ,  0.52213911,  0.45880561,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  0.10452846,\n",
       "        0.9945219 ,  0.74314483,  0.66913061,  0.80901699, -0.58778525,\n",
       "        0.91354546, -0.40673664,  0.10452846,  0.9945219 ,  0.74314483,\n",
       "        0.66913061,  0.74314483, -0.66913061,  0.80901699, -0.58778525])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf2f3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.811597719136753"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_lin = LinearRegression()\n",
    "\n",
    "cross_val_score(model_lin, X_train_scaled, y_train, cv=10, scoring='neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba3d639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13767465431135817"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lin.fit(X_train_scaled, y_train)\n",
    "model_lin.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1fdd774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.217196101654763"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(max_depth=10, n_estimators=500, learning_rate=0.01, n_jobs = -1)\n",
    "cross_val_score(model_xgb, X_train_scaled, y_train, cv=10, scoring='neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8a51828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.301517791919063"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.fit(X_train_scaled, y_train)\n",
    "model_xgb.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d94ee58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-05 14:44:27] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 12-05 14:44:27] {1690} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 12-05 14:44:28] {1788} INFO - Minimizing error metric: rmse\n",
      "[flaml.automl.logger: 12-05 14:44:28] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2344} INFO - Estimated sufficient time budget=16445s. Estimated necessary time budget=16s.\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.3s,\testimator xgboost's best error=5.3670,\tbest estimator xgboost's best error=5.3670\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.4s,\testimator xgboost's best error=4.8958,\tbest estimator xgboost's best error=4.8958\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.4s,\testimator xgboost's best error=4.8958,\tbest estimator xgboost's best error=4.8958\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.5s,\testimator xgboost's best error=4.8104,\tbest estimator xgboost's best error=4.8104\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.6s,\testimator xgboost's best error=4.7890,\tbest estimator xgboost's best error=4.7890\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.7s,\testimator xgboost's best error=4.7890,\tbest estimator xgboost's best error=4.7890\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.8s,\testimator xgboost's best error=4.6993,\tbest estimator xgboost's best error=4.6993\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.8s,\testimator xgboost's best error=4.6698,\tbest estimator xgboost's best error=4.6698\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 0.9s,\testimator xgboost's best error=4.6631,\tbest estimator xgboost's best error=4.6631\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2391} INFO -  at 1.0s,\testimator xgboost's best error=4.6631,\tbest estimator xgboost's best error=4.6631\n",
      "[flaml.automl.logger: 12-05 14:44:28] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2391} INFO -  at 1.1s,\testimator xgboost's best error=4.5643,\tbest estimator xgboost's best error=4.5643\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2391} INFO -  at 1.3s,\testimator xgboost's best error=4.5643,\tbest estimator xgboost's best error=4.5643\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2391} INFO -  at 1.4s,\testimator xgboost's best error=4.5643,\tbest estimator xgboost's best error=4.5643\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2391} INFO -  at 2.0s,\testimator xgboost's best error=4.5643,\tbest estimator xgboost's best error=4.5643\n",
      "[flaml.automl.logger: 12-05 14:44:29] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2391} INFO -  at 2.2s,\testimator xgboost's best error=4.5342,\tbest estimator xgboost's best error=4.5342\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2391} INFO -  at 2.6s,\testimator xgboost's best error=4.5342,\tbest estimator xgboost's best error=4.5342\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2391} INFO -  at 2.7s,\testimator xgboost's best error=4.5342,\tbest estimator xgboost's best error=4.5342\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2391} INFO -  at 2.8s,\testimator xgboost's best error=4.5342,\tbest estimator xgboost's best error=4.5342\n",
      "[flaml.automl.logger: 12-05 14:44:30] {2218} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:31] {2391} INFO -  at 3.3s,\testimator xgboost's best error=4.5342,\tbest estimator xgboost's best error=4.5342\n",
      "[flaml.automl.logger: 12-05 14:44:31] {2218} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:31] {2391} INFO -  at 3.9s,\testimator xgboost's best error=4.2716,\tbest estimator xgboost's best error=4.2716\n",
      "[flaml.automl.logger: 12-05 14:44:31] {2218} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:32] {2391} INFO -  at 4.4s,\testimator xgboost's best error=4.2716,\tbest estimator xgboost's best error=4.2716\n",
      "[flaml.automl.logger: 12-05 14:44:32] {2218} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:33] {2391} INFO -  at 5.3s,\testimator xgboost's best error=4.1684,\tbest estimator xgboost's best error=4.1684\n",
      "[flaml.automl.logger: 12-05 14:44:33] {2218} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:33] {2391} INFO -  at 6.0s,\testimator xgboost's best error=4.1684,\tbest estimator xgboost's best error=4.1684\n",
      "[flaml.automl.logger: 12-05 14:44:33] {2218} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:35] {2391} INFO -  at 7.7s,\testimator xgboost's best error=4.1684,\tbest estimator xgboost's best error=4.1684\n",
      "[flaml.automl.logger: 12-05 14:44:35] {2218} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:38] {2391} INFO -  at 10.6s,\testimator xgboost's best error=4.1684,\tbest estimator xgboost's best error=4.1684\n",
      "[flaml.automl.logger: 12-05 14:44:38] {2218} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:39] {2391} INFO -  at 11.3s,\testimator xgboost's best error=4.1684,\tbest estimator xgboost's best error=4.1684\n",
      "[flaml.automl.logger: 12-05 14:44:39] {2218} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:42] {2391} INFO -  at 14.6s,\testimator xgboost's best error=4.1188,\tbest estimator xgboost's best error=4.1188\n",
      "[flaml.automl.logger: 12-05 14:44:42] {2218} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:43] {2391} INFO -  at 15.4s,\testimator xgboost's best error=4.1188,\tbest estimator xgboost's best error=4.1188\n",
      "[flaml.automl.logger: 12-05 14:44:43] {2218} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:49] {2391} INFO -  at 21.7s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:44:49] {2218} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:44:53] {2391} INFO -  at 25.2s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:44:53] {2218} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:45:00] {2391} INFO -  at 32.6s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:00] {2218} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:45:07] {2391} INFO -  at 39.4s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:07] {2218} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:45:10] {2391} INFO -  at 42.9s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:10] {2218} INFO - iteration 33, current learner xgboost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-05 14:45:11] {2391} INFO -  at 44.0s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:11] {2218} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:45:37] {2391} INFO -  at 69.5s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:37] {2218} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:45:55] {2391} INFO -  at 87.3s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:55] {2218} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:45:58] {2391} INFO -  at 90.4s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:45:58] {2218} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:46:06] {2391} INFO -  at 98.5s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:46:06] {2218} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:46:09] {2391} INFO -  at 101.3s,\testimator xgboost's best error=3.9954,\tbest estimator xgboost's best error=3.9954\n",
      "[flaml.automl.logger: 12-05 14:46:09] {2218} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:46:15] {2391} INFO -  at 107.4s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:46:15] {2218} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:46:19] {2391} INFO -  at 112.0s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:46:19] {2218} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:46:22] {2391} INFO -  at 114.3s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:46:22] {2218} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:46:42] {2391} INFO -  at 135.0s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:46:42] {2218} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:47:19] {2391} INFO -  at 171.5s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:47:19] {2218} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:47:22] {2391} INFO -  at 174.8s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:47:22] {2218} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:47:36] {2391} INFO -  at 189.0s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:47:36] {2218} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:47:40] {2391} INFO -  at 192.1s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:47:40] {2218} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:47:42] {2391} INFO -  at 194.2s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:47:42] {2218} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:48:01] {2391} INFO -  at 213.5s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:48:01] {2218} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:02] {2391} INFO -  at 274.8s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:49:02] {2218} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:03] {2391} INFO -  at 275.8s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:49:03] {2218} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:10] {2391} INFO -  at 282.9s,\testimator xgboost's best error=3.9853,\tbest estimator xgboost's best error=3.9853\n",
      "[flaml.automl.logger: 12-05 14:49:10] {2218} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:16] {2391} INFO -  at 288.4s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:49:16] {2218} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:19] {2391} INFO -  at 291.6s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:49:19] {2218} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:34] {2391} INFO -  at 306.8s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:49:34] {2218} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:55] {2391} INFO -  at 328.0s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:49:55] {2218} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:49:58] {2391} INFO -  at 330.7s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:49:58] {2218} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:50:35] {2391} INFO -  at 367.3s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:50:35] {2218} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:50:37] {2391} INFO -  at 369.1s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:50:37] {2218} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:50:58] {2391} INFO -  at 390.0s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:50:58] {2218} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:50:59] {2391} INFO -  at 391.9s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:50:59] {2218} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:04] {2391} INFO -  at 396.5s,\testimator xgboost's best error=3.9349,\tbest estimator xgboost's best error=3.9349\n",
      "[flaml.automl.logger: 12-05 14:51:04] {2218} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:13] {2391} INFO -  at 405.4s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:51:13] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:21] {2391} INFO -  at 414.0s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:51:21] {2218} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:33] {2391} INFO -  at 425.7s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:51:33] {2218} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:41] {2391} INFO -  at 433.8s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:51:41] {2218} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:53] {2391} INFO -  at 445.4s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:51:53] {2218} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:51:57] {2391} INFO -  at 449.3s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:51:57] {2218} INFO - iteration 68, current learner xgboost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-05 14:52:23] {2391} INFO -  at 475.1s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:52:23] {2218} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:52:30] {2391} INFO -  at 482.1s,\testimator xgboost's best error=3.9199,\tbest estimator xgboost's best error=3.9199\n",
      "[flaml.automl.logger: 12-05 14:52:30] {2218} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:52:42] {2391} INFO -  at 494.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:52:42] {2218} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:53:23] {2391} INFO -  at 535.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:53:23] {2218} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:53:28] {2391} INFO -  at 541.0s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:53:28] {2218} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:53:32] {2391} INFO -  at 544.9s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:53:32] {2218} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:54:47] {2391} INFO -  at 619.7s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:54:47] {2218} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:55:54] {2391} INFO -  at 686.3s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:55:54] {2218} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:55:58] {2391} INFO -  at 690.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:55:58] {2218} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:56:37] {2391} INFO -  at 729.2s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:56:37] {2218} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:56:42] {2391} INFO -  at 734.7s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:56:42] {2218} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:56:57] {2391} INFO -  at 749.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:56:57] {2218} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:57:16] {2391} INFO -  at 768.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:57:16] {2218} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:57:33] {2391} INFO -  at 785.5s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:57:33] {2218} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:57:50] {2391} INFO -  at 802.5s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:57:50] {2218} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:57:58] {2391} INFO -  at 810.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:57:58] {2218} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:58:32] {2391} INFO -  at 844.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:58:32] {2218} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:58:56] {2391} INFO -  at 868.5s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:58:56] {2218} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:59:05] {2391} INFO -  at 877.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:59:05] {2218} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:59:26] {2391} INFO -  at 898.3s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:59:26] {2218} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:59:38] {2391} INFO -  at 910.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:59:38] {2218} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 14:59:41] {2391} INFO -  at 913.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 14:59:41] {2218} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:01:33] {2391} INFO -  at 1025.3s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:01:33] {2218} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:01:46] {2391} INFO -  at 1038.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:01:46] {2218} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:02:17] {2391} INFO -  at 1069.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:02:17] {2218} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:02:25] {2391} INFO -  at 1077.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:02:25] {2218} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:02:58] {2391} INFO -  at 1110.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:02:58] {2218} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:03:10] {2391} INFO -  at 1122.2s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:03:10] {2218} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:03:27] {2391} INFO -  at 1139.5s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:03:27] {2218} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:03:45] {2391} INFO -  at 1157.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:03:45] {2218} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:03:55] {2391} INFO -  at 1167.2s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:03:55] {2218} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:04:01] {2391} INFO -  at 1173.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:04:01] {2218} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:04:27] {2391} INFO -  at 1199.9s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:04:27] {2218} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:04:42] {2391} INFO -  at 1214.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:04:42] {2218} INFO - iteration 102, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:04:53] {2391} INFO -  at 1225.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:04:53] {2218} INFO - iteration 103, current learner xgboost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-05 15:05:33] {2391} INFO -  at 1265.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:05:33] {2218} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:05:39] {2391} INFO -  at 1271.3s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:05:39] {2218} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:06:05] {2391} INFO -  at 1297.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:06:05] {2218} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:06:12] {2391} INFO -  at 1304.9s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:06:12] {2218} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:06:19] {2391} INFO -  at 1311.3s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:06:19] {2218} INFO - iteration 108, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:06:46] {2391} INFO -  at 1338.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:06:46] {2218} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:06:55] {2391} INFO -  at 1347.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:06:55] {2218} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:07:17] {2391} INFO -  at 1369.3s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:07:17] {2218} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:07:58] {2391} INFO -  at 1410.7s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:07:58] {2218} INFO - iteration 112, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:08:03] {2391} INFO -  at 1415.6s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:08:03] {2218} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:08:12] {2391} INFO -  at 1424.7s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:08:12] {2218} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:08:33] {2391} INFO -  at 1445.9s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:08:33] {2218} INFO - iteration 115, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:09:11] {2391} INFO -  at 1483.0s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:09:11] {2218} INFO - iteration 116, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:09:18] {2391} INFO -  at 1490.2s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:09:18] {2218} INFO - iteration 117, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:09:25] {2391} INFO -  at 1497.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:09:25] {2218} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:10:02] {2391} INFO -  at 1534.9s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:10:02] {2218} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:10:25] {2391} INFO -  at 1557.2s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:10:25] {2218} INFO - iteration 120, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:10:39] {2391} INFO -  at 1571.4s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:10:39] {2218} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:10:52] {2391} INFO -  at 1584.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:10:52] {2218} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:11:19] {2391} INFO -  at 1611.1s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:11:19] {2218} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:13:24] {2391} INFO -  at 1736.4s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:13:24] {2218} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:13:26] {2391} INFO -  at 1738.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:13:26] {2218} INFO - iteration 125, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:13:33] {2391} INFO -  at 1745.8s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:13:33] {2218} INFO - iteration 126, current learner xgboost\n",
      "[flaml.automl.logger: 12-05 15:14:28] {2391} INFO -  at 1800.4s,\testimator xgboost's best error=3.9122,\tbest estimator xgboost's best error=3.9122\n",
      "[flaml.automl.logger: 12-05 15:15:00] {2627} INFO - retrain xgboost for 31.7s\n",
      "[flaml.automl.logger: 12-05 15:15:00] {2630} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=[],\n",
      "             colsample_bylevel=0.7555188937457962, colsample_bynode=1,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
      "             grow_policy='lossguide', importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.045196541097708605,\n",
      "             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=0,\n",
      "             max_leaves=579, min_child_weight=20.183997375977096, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=268, n_jobs=-1,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "             reg_alpha=8.684578481210897, reg_lambda=0.0009765625, ...)\n",
      "[flaml.automl.logger: 12-05 15:15:00] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 12-05 15:15:00] {1931} INFO - Time taken to find the best model: 494.7689142227173\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 1800,  # total running time in seconds\n",
    "    \"metric\": 'rmse',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"estimator_list\": ['xgboost'],  # list of ML learners; we tune XGBoost in this example\n",
    "    \"task\": 'regression',  # task type\n",
    "    \"log_file_name\": 'train_delays.log',  # flaml log file\n",
    "    \"seed\": 37,  # random seed\n",
    "}\n",
    "automl.fit(X_train=X_train_scaled, y_train=y_train, **settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "494861bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "nn = Sequential()\n",
    "nn.add(layers.Dense(70, input_dim = X_train_scaled.shape[1], activation='relu')) \n",
    "nn.add(layers.Dense(140, activation='relu'))\n",
    "nn.add(layers.Dense(50, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6bfd3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 140)               9940      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                7050      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,011\n",
      "Trainable params: 22,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80d7e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 15:50:05.485561: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 77341600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8632/8632 [==============================] - 24s 3ms/step - loss: 22.4926 - mae: 1.8874 - val_loss: 22.3038 - val_mae: 1.8248\n",
      "Epoch 2/1000\n",
      "8632/8632 [==============================] - 27s 3ms/step - loss: 21.3211 - mae: 1.8355 - val_loss: 20.7805 - val_mae: 1.8060\n",
      "Epoch 3/1000\n",
      "8632/8632 [==============================] - 21s 2ms/step - loss: 20.9541 - mae: 1.8267 - val_loss: 20.4158 - val_mae: 1.7238\n",
      "Epoch 4/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 20.3819 - mae: 1.8151 - val_loss: 20.3121 - val_mae: 1.7777\n",
      "Epoch 5/1000\n",
      "8632/8632 [==============================] - 21s 2ms/step - loss: 19.9943 - mae: 1.8082 - val_loss: 23.3725 - val_mae: 1.9901\n",
      "Epoch 6/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 19.9306 - mae: 1.8028 - val_loss: 22.5511 - val_mae: 1.8183\n",
      "Epoch 7/1000\n",
      "8632/8632 [==============================] - 19s 2ms/step - loss: 19.4533 - mae: 1.7980 - val_loss: 22.4087 - val_mae: 1.8349\n",
      "Epoch 8/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 19.6169 - mae: 1.7945 - val_loss: 20.2224 - val_mae: 1.8747\n",
      "Epoch 9/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 19.2780 - mae: 1.7964 - val_loss: 20.0514 - val_mae: 1.8331\n",
      "Epoch 10/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 19.3731 - mae: 1.7955 - val_loss: 20.6045 - val_mae: 1.8247\n",
      "Epoch 11/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 19.2500 - mae: 1.7894 - val_loss: 20.7493 - val_mae: 1.8730\n",
      "Epoch 12/1000\n",
      "8632/8632 [==============================] - 18s 2ms/step - loss: 19.2429 - mae: 1.7891 - val_loss: 20.3314 - val_mae: 1.7738\n",
      "Epoch 13/1000\n",
      "8632/8632 [==============================] - 17s 2ms/step - loss: 19.1186 - mae: 1.7865 - val_loss: 20.1715 - val_mae: 1.7963\n",
      "Epoch 14/1000\n",
      "8632/8632 [==============================] - 17s 2ms/step - loss: 18.8981 - mae: 1.7837 - val_loss: 20.2339 - val_mae: 1.9720\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "nn.compile(loss='mse', \n",
    "              optimizer='adam', \n",
    "              metrics=['mae'])\n",
    "\n",
    "history = nn.fit(X_train_scaled, y_train,\n",
    "          validation_split=0.2, \n",
    "          batch_size=32,\n",
    "          epochs=1000,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9914784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291059     2.0\n",
       "26152      3.0\n",
       "58725      0.0\n",
       "364447     4.0\n",
       "92290     10.0\n",
       "          ... \n",
       "471089     1.0\n",
       "358705     3.0\n",
       "467571     1.0\n",
       "263639     1.5\n",
       "67847      4.0\n",
       "Name: PFPI_MINUTES, Length: 147976, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93b308f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12/4625 [..............................] - ETA: 21s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 15:56:09.294173: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 41433280 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4625/4625 [==============================] - 5s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb574aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270.26743030548096"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, max_error\n",
    "\n",
    "max_error(y_true=y_test, y_pred=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
